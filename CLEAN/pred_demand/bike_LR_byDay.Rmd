---
title: "Linear Regression Analysis of the Bike Dataset"
author: "Tessa Liew Lee Yi"
date: "9/11/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Seoul Bike Rent Counts by Day

```{r, include = FALSE}
library(MASS)
library(tidyverse)

#install.packages("corrplot")
library(corrplot)

```


# Overview on the Seoul Bike Dataset
 Objective: 
 i. Determine what is the relationship between the number of bikes rented with each of the predictor variables
 ii. fit a model to predict the rent count for the next financial period.
```{r bike, echo = FALSE}
bike <- read.csv("../data/bike_clean_rep.csv")

bike$holiday <- as.factor(bike$holiday)
bike$season <- as.factor(bike$season)
bike$date <- as.Date(bike$date, format = "%Y-%m-%d")

head(bike)

```

```{r seoul_bike, include = FALSE}

seoul_bike <- bike[,-c(1, 2, 14, 15)]
seoul_bike <- seoul_bike %>%
    filter(rent_count >0)
attach(seoul_bike)

```

From the correlation plot, we can see that temperature is highly positively correlated to dewpoint_temp and solar_radiation and negatively correlated to wind_speed.
Besides that, we can see that dewpoint_temp is highly correlated to humidity and solar_radiation. Also, humidity and visibility are highly negatively correlated. 
From these observations, we can add interaction terms in out fitted model to improve the fit.

```{r, echo = FALSE}

bike_quantitative <- c(5,6,7,8,9,10,11,12,13)
pairs(bike[,bike_quantitative], main = "Correlation between Quantitative Variables in Bike Dataset", pch = 21)
bike_cor <- cor(bike[,bike_quantitative])
bike_cor
corrplot(bike_cor, type = "upper", order = "hclust", diag = TRUE,
         tl.col = "black", tl.srt = 45,tl.cex = 1)

```
#Splitting the data into training and test data
```{r}
set.seed(43)
train <- sample(1:353, 285)

bike_train <- seoul_bike[train,]   

bike_test <- seoul_bike[-train,]   



```
Fitting linear regression models
Model 1: Full model
observation: Many insignificant variables
Adjusted R-squared value is relatively high. However, unreliable because of multicolinearity
From the regression analysis, we can see that the linearity assumption and constant variance assumption have been violated. 
Therefore, we perform transformation on the response and fit a new model. Also, we add interaction terms and use mixed step-wise selection for variable selection. 
```{r model_1, echo = FALSE}

model_1 <- lm(data = bike_train, rent_count ~ .)
summary(model_1)
anova(model_1)
par(mfrow = c(2,2))
plot(model_1)

```

```{r model_2, include=FALSE}

model_2 <- lm(data = bike_train, rent_count ~ temperature + humidity + wind_speed + visibility +
                solar_radiation + rainfall + snowfall +season + holiday)

summary(model_2)
anova(model_2)

```


```{r model_3, include = FALSE}


model_3 <- lm(data = bike_train, rent_count ~ temperature + humidity + wind_speed + 
                solar_radiation + rainfall + snowfall +season + holiday)

summary(model_3)
anova(model_3)


```

```{r model_4, include = FALSE}


model_4 <- lm(data = bike_train, rent_count ~ temperature + humidity + 
                solar_radiation + rainfall + snowfall +season + holiday)

summary(model_4)
anova(model_4)


```

```{r model_5, include = FALSE}


model_5 <- lm(data = bike_train, rent_count ~ temperature + humidity + 
                solar_radiation + rainfall + snowfall +season + holiday + humidity*rainfall +
                snowfall*temperature + humidity*wind_speed)

summary(model_5)
anova(model_5)


```

# Transformation of Response using Boxcox Method
From Figure 3.XXX, we can see that the 
Transformation for response is either a log or sqrt transformation. 
We then fit the full model again with log(response) and sqrt(response) separately and use mixed step-wise selection to chose the best variables
```{r model, echo  = FALSE}
boxcox(model_1, lambda = seq(-2,2, by = 0.5), plotit = TRUE)
```

```{r model_6, include = FALSE}


model_6 <- lm(formula = log(rent_count) ~ temperature + humidity + solar_radiation + 
    rainfall + snowfall + season + holiday + wind_speed + visibility + dewpoint_temp, data = bike_train)

summary(model_6)
anova(model_6)


# Residual plot
plot(model_6$fitted.values, rstandard(model_6), xlab = "Fitted Values",
     ylab = "Standardized Residuals", main = "Bike Count Model", pch = 20)
abline(h=0) #quadratic curve

# The residual plot displays a funnel shape. Hence, it shows unconstnt variance, trnasformation of data is required.

## Normal Probability Plot
qqnorm(rstandard(model_6), datax = TRUE, ylab = "Standardized Residuals", xlab = "z scores")
qqline(rstandard(model_6), datax = TRUE)


step(model_6, direction = "both")
```

```{r model_7, include=FALSE}

model_7 <- lm(formula = log(rent_count) ~ humidity + solar_radiation + rainfall + 
    snowfall + season + holiday + wind_speed + dewpoint_temp, 
    data = bike_train)
summary(model_7)
anova(model_7)

# Residual plot
plot(model_7$fitted.values, rstandard(model_7), xlab = "Fitted Values",
     ylab = "Standardized Residuals", main = "Bike Count Model", pch = 20)
abline(h=0) #quadratic curve

# The residual plot displays a funnel shape. Hence, it shows unconstnt variance, trnasformation of data is required.

## Normal Probability Plot
qqnorm(rstandard(model_7), datax = TRUE, ylab = "Standardized Residuals", xlab = "z scores")
qqline(rstandard(model_7), datax = TRUE)


plot(model_7)

```

```{r model_8, include = FALSE}


model_8 <- lm(formula = sqrt(rent_count) ~ temperature + humidity + solar_radiation + 
    rainfall + snowfall + season + holiday + wind_speed + visibility + dewpoint_temp, data = bike_train)

summary(model_8)
anova(model_8)


# Residual plot
plot(model_8$fitted.values, rstandard(model_8), xlab = "Fitted Values",
     ylab = "Standardized Residuals", main = "Bike Count Model", pch = 20)
abline(h=0) #quadratic curve

# The residual plot displays a funnel shape. Hence, it shows unconstnt variance, trnasformation of data is required.

## Normal Probability Plot
qqnorm(rstandard(model_8), datax = TRUE, ylab = "Standardized Residuals", xlab = "z scores")
qqline(rstandard(model_8), datax = TRUE)

plot(model_8)

step(model_8, direction = "both")

```

```{r model_9, include = FALSE}

model_9 <- lm(formula = sqrt(rent_count) ~ humidity + solar_radiation + 
    rainfall + snowfall + season + holiday + wind_speed + dewpoint_temp, 
    data = bike_train)

summary(model_9)
anova(model_9)

```
# Adding in the interaction terms for suspected multicolinearity and perform Variable Selection
```{r model_10, include = FALSE}

model_10 <- lm(formula = log(rent_count) ~ humidity + solar_radiation + 
    rainfall + snowfall + season + holiday + wind_speed + dewpoint_temp +
    humidity:dewpoint_temp + dewpoint_temp:solar_radiation + rainfall:humidity, 
    data = bike_train)

summary(model_10)
anova(model_10)

plot(model_10)

step(model_10, direction = "both")


```
## Final Training Model: Model_11
After variable selection and tranformation, the fitted linear regression model is given by: 
log(rent_count) = 10.2602028 - 0.010097*humidity + 2.1186095*solar_radiation - 0.0222518*rainfall - 0.0005785*snowfall - 
                  0.4292133*I(season = Spring) - 0.2518283*I(season = Summer) - 0.8805229*I(season = Winter) + 
                  0.2674261*I(holiday = No Holiday) - 0.0640792*wind_speed + 0.0328645*dewpoint_temp -   
                  0.1074402*solar_radiation*dewpoint_temp
From the Residual plot and Leverage plot, we can see that there are a few outliers (eg. points 126, 269 and 332) and a few unusual high leverage points (eg. points 143, 269 and 332). 

```{r model_11}

model_11 <- lm(formula = log(rent_count) ~ humidity + solar_radiation + rainfall + 
    snowfall + season + holiday + wind_speed + dewpoint_temp + 
    solar_radiation:dewpoint_temp, data = bike_train)

summary(model_11)
anova(model_11)

par(mfrow = c(2,2))
plot(model_11)

step(model_11, direction = "both")


```

## Training Mean Absolute Percentage Error
The Mean Percentage Error of our final fitted model is 22.25%. 
```{r}


pred_train <- exp(model_11$fitted.values)
MPE_training<-mean(abs(bike_train$rent_count-pred_train)/bike_train$rent_count)
MPE_training

```

## Final Prediction Model: Model_12
```{r model_12}

model_12 <- lm(formula = log(rent_count) ~ humidity + solar_radiation + rainfall + 
    snowfall + season + holiday + wind_speed + dewpoint_temp + 
    solar_radiation:dewpoint_temp, data = bike_test)

summary(model_12)
anova(model_12)

```

## Test Mean Absolute Percentage Error
```{r MPE_test}

pred_test <- exp(model_12$fitted.values)
MPE_test <- mean(abs(bike_test$rent_count-pred_test)/bike_test$rent_count)
MPE_test

```
