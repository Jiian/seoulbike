---
title: "randomforest_feature_engineering"
author: "Group 15"
date: "2021/9/1"
output: html_document
---
```{r}
rm(list=ls())
library(randomForest)
library(tidyverse)
library(ggplot2)
auto<-read.csv("./seoul_bike_agg_mean_FG.csv")
demo<-read.csv("./7days_demo_FG.csv")
```

```{r}
getDT<-function(x,title=""){
  set.seed(12)
  select<-sample(1:nrow(x),length(x$rent_count)*0.8)
  train=x[select,]
  test=x[-select,]
  train.forest<-randomForest(rent_count~.,
                             data=train,
                             importance=TRUE, 
                             ntree=100)
  pred<-predict(train.forest,test)
  MSR<-sqrt(mean((test$rent_count-pred)**2))
  gg<-data.frame(x=pred,
                 y=test$rent_count)
  print(ggplot(gg,aes(x,y))+
          geom_point()+
          geom_abline()+
          geom_smooth(method = "lm",
                      span=10,
                      se=FALSE)+
          labs(title = title,
               x = 'predicted rent count', 
               y = 'actual rent count')+
          theme(panel.grid = element_blank(), 
                panel.background = element_rect(color = 'black', 
                                                fill = 'transparent'),
                plot.title = element_text(hjust = 0.5)))
  print(train.forest)#summary of table
  print(train%>%select(-rent_count)%>%colnames())#features names
  print(paste("RMSE:",MSR))#RMSE
  list(train.forest,train)
}

DT<-getDT(auto)

```

```{r}
#Cross validation
#perform 5 times with 10 folds
train<-DT[[2]]
Train.cv <- replicate(5,
                      rfcv(train[-ncol(train)], train$rent_count, cv.fold = 10, step=1.5),
                      simplify = FALSE)

#Table and Plot 
#No. features VS cross validation errors 
train.cv <- data.frame(sapply(Train.cv, '[[', "error.cv"))
train.cv$features <- rownames(train.cv)
train.cv <- gather(train.cv,
                   key="key",
                   value="value",
                   -features)
train.cv$features <- as.numeric(as.character(train.cv$features))
train.cv.mean <- aggregate(train.cv$value, 
                           by = list(train.cv$features), 
                           FUN = mean)[-c(13,14,15),]

colnames(train.cv.mean)<-(c("Number_of_Features","Mean_of_Squared_Residual"))
head(train.cv.mean, 15)#lowest x when 5 features
ggplot(train.cv.mean, 
       aes(Number_of_Features, 
           Mean_of_Squared_Residual)) +
  geom_line() +
  theme(panel.grid = element_blank(), 
        panel.background = element_rect(color = 'black', 
                                        fill = 'transparent'),
        plot.title = element_text(hjust = 0.5)) +
  labs(title = '#Features vs. Error',
       x = 'Number of Features', 
       y = 'Mean of squared residual')
```
```{r}
#Plot of variable importance
#2 standards: Increasing of MSE and Increasing node purity
varImpPlot(DT[[1]], 
           n.var = 5, 
           type = 2,
           main = 'Top 10 - variable importance',
           cex=0.7)
```
```{r}
# extracts two sets each contains 5 features corresponding to the top 5 increasing node purity
important_features<-data.frame(importance(DT[[1]]), check.names = FALSE)

features_purity <- important_features[order(important_features$IncNodePurity, 
                                            decreasing = TRUE), ][c(1:5),]%>%rownames()
DTpurity<-getDT(auto%>%select(c(rent_count,all_of(features_purity))),title="top5 incnodepurity")

```
```{r}
# predicted rent count for 7days demo
predict(DTpurity[[1]],demo)
```



